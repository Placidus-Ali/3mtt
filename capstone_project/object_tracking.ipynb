{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e271597d-4c15-4ce2-95c9-8f13320565cd",
   "metadata": {},
   "source": [
    "### Object Tracking in Video Feeds for Traffic Monitoring\n",
    "\n",
    "Built an object tracking system to monitor and count vehicles and other objects in a video feed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b5d09-8689-4620-b9d9-aa8f0abb6d4f",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59325609-c05f-4315-bcad-4e94e526909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python numpy torch torchvision yolov5 filterpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8f25c5a-6417-410e-a99a-7d5cee5db1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas\n",
    "import torchvision\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from sort import Sort\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38b075-eaa8-4eda-9777-e440d0c66455",
   "metadata": {},
   "source": [
    "##### Loading the Pre-trained Object Detection Model YOLOv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65221836-3550-4f25-93f7-b92530f9c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#git clone https://github.com/ultralytics/yolov5.git\n",
    "#cd yolov5\n",
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420d765b-28b5-4fdc-b0ae-59edb05b7003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\STUTERN/.cache\\torch\\hub\\ultralytics_yolov5_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['gitpython>=3.1.30', 'setuptools>=70.0.0'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  AutoUpdate skipped (offline)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2024-11-23 Python-3.10.11 torch-2.5.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # Load small YOLOv5 model\n",
    "\n",
    "# Define a function for object detection\n",
    "def detect_objects(frame):\n",
    "    results = model(frame)\n",
    "    detections = results.pandas().xyxy[0]  # Convert to pandas dataframe\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9950b8a-a69a-4443-86cd-c56ec5177f43",
   "metadata": {},
   "source": [
    "#### Loading and processing Video Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad0e751a-0b9a-4d00-aac7-0b0199f8d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"traffic_video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc4f6d-056b-4649-810e-606b692c582c",
   "metadata": {},
   "source": [
    "##### Iterate through video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "844ead70-c014-4975-806e-a9f4b9c9ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame for faster processing\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "\n",
    "    # Detect objects\n",
    "    detections = detect_objects(resized_frame)\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for _, row in detections.iterrows():\n",
    "        x1, y1, x2, y2, conf, cls = map(int, row[['xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class']])\n",
    "        label = f\"{row['name']} {conf:.2f}\"\n",
    "        cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(resized_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Traffic Feed\", resized_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75f29e",
   "metadata": {},
   "source": [
    "##### Implementing Tracking Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87685582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#git clone https://github.com/abewley/sort.git\n",
    "#cd sort\n",
    "#pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c50e7",
   "metadata": {},
   "source": [
    "##### Integrating SORT for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3572cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SORT tracker\n",
    "tracker = Sort()\n",
    "\n",
    "def track_objects(detections):\n",
    "    tracked_objects = tracker.update(detections[['xmin', 'ymin', 'xmax', 'ymax', 'confidence']].values)\n",
    "    return tracked_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7966254a",
   "metadata": {},
   "source": [
    "##### Combine detection and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c79cd864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SORT tracker\n",
    "tracker = Sort()\n",
    "\n",
    "# Counting line and vehicle count\n",
    "counting_line = 300  # Y-coordinate for counting line\n",
    "vehicle_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    resized_frame = cv2.resize(frame, (640, 360))\n",
    "    detections = detect_objects(resized_frame)\n",
    "\n",
    "    # Convert to NumPy for SORT\n",
    "    detection_array = detections[['xmin', 'ymin', 'xmax', 'ymax', 'confidence']].values\n",
    "    tracked_objects = track_objects(detection_array)\n",
    "\n",
    "    # Draw tracked objects\n",
    "    for obj in tracked_objects:\n",
    "        x1, y1, x2, y2, obj_id = map(int, obj)\n",
    "        label = f\"ID {obj_id}\"\n",
    "        cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        cv2.putText(resized_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        # Counting vehicles that cross the line\n",
    "        center_y = (y1 + y2) // 2\n",
    "        if center_y > counting_line - 10 and center_y < counting_line + 10:\n",
    "            vehicle_count += 1\n",
    "\n",
    "    # Display vehicle count on the frame\n",
    "    cv2.putText(resized_frame, f\"Count: {vehicle_count}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    # Show the frame with tracked objects\n",
    "    cv2.imshow(\"Tracked Traffic Feed\", resized_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c166a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
